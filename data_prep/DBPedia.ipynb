{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"s3a://final-kmeans/raw/lat_longs.txt\"\n",
    "# filepath = \"/home/adrian/6007_Final/data/lat_longs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a text file and convert each line to a Row.\n",
    "lines = sc.textFile(filepath) # , use_unicode=False\n",
    "lines.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip white space from beginning and end of lines\n",
    "stripped = lines.map(lambda l: l.strip())\n",
    "# Split by spaces\n",
    "split = stripped.map(lambda s: s.split(' '))\n",
    "# latlong = split.map(lambda items: (float(items[0]),float(items[1]),items[2])) # ,items[2]\n",
    "latlong = split.map(lambda items: (items[0],items[1],items[2])) # ,items[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'36.7 3.216666666666667 <http://dbpedia.org/resource/Algeria>',\n",
       " u'42.5 1.5166666666666666 <http://dbpedia.org/resource/Andorra>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stripped.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'36.7', u'3.216666666666667', u'<http://dbpedia.org/resource/Algeria>'],\n",
       " [u'42.5', u'1.5166666666666666', u'<http://dbpedia.org/resource/Andorra>']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View an entry\n",
    "split.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'36.7', u'3.216666666666667', u'<http://dbpedia.org/resource/Algeria>'),\n",
       " (u'42.5', u'1.5166666666666666', u'<http://dbpedia.org/resource/Andorra>')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View an entry\n",
    "latlong.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: string, _2: string, _3: string]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe and persist to prevent calling to the S3 bucket for every operation\n",
    "df_pedia = spark.createDataFrame(latlong)\n",
    "df_pedia.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+--------------------+\n",
      "|                _1|                _2|                  _3|\n",
      "+------------------+------------------+--------------------+\n",
      "|              36.7| 3.216666666666667|<http://dbpedia.o...|\n",
      "|              42.5|1.5166666666666666|<http://dbpedia.o...|\n",
      "|12.516666666666667|-70.03333333333333|<http://dbpedia.o...|\n",
      "|-8.833333333333334|13.333333333333334|<http://dbpedia.o...|\n",
      "|41.333333333333336|              19.8|<http://dbpedia.o...|\n",
      "| 34.53333333333333| 69.13333333333334|<http://dbpedia.o...|\n",
      "|40.416666666666664|49.833333333333336|<http://dbpedia.o...|\n",
      "| 39.93333333333333| 32.86666666666667|<http://dbpedia.o...|\n",
      "| 52.36666666666667|               4.9|<http://dbpedia.o...|\n",
      "|             50.46|              2.13|<http://dbpedia.o...|\n",
      "|17.116666666666667|            -61.85|<http://dbpedia.o...|\n",
      "| 57.04638888888889| 9.919166666666667|<http://dbpedia.o...|\n",
      "|             56.15|10.216666666666667|<http://dbpedia.o...|\n",
      "|            34.929|           138.601|<http://dbpedia.o...|\n",
      "| 42.03472222222222|            -93.62|<http://dbpedia.o...|\n",
      "| 33.41972222222222|           43.3125|<http://dbpedia.o...|\n",
      "|16.863611111111112|          -99.8825|<http://dbpedia.o...|\n",
      "| 50.78333333333333| 6.083333333333333|<http://dbpedia.o...|\n",
      "|           57.1526|             -2.11|<http://dbpedia.o...|\n",
      "|36.766666666666666| 3.216666666666667|<http://dbpedia.o...|\n",
      "+------------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View dataframe\n",
    "df_pedia.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns and impose appropriate names and datatypes\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_pedia = df_pedia.selectExpr('cast(_1 as float) as latitude', 'cast(_2 as float) as longitude',\n",
    "                          '_3 as name_of_page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(latitude,FloatType,true),StructField(longitude,FloatType,true),StructField(name_of_page,StringType,true)))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View dataframe schema to confirm proper datatypes\n",
    "df_pedia.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to S3 bucket as a csv file\n",
    "outpath = 's3a://final-kmeans/clean'\n",
    "df_pedia.coalesce(1).write.csv(outpath+'/dbpedia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random subset for later steps - Take random 20% of samples as subset\n",
    "df_pedia.coalesce(1).sample(False, .2).write.csv(outpath+'/dbpedia_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
